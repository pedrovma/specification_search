{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6959b4d1",
   "metadata": {},
   "source": [
    "# STGE Specification Search with GNS DGP - AK test\n",
    "\n",
    "Implements the classic STGE strategy for a GNS DGP with varying values for $\\gamma$, $\\rho$ and $\\lambda$ when the model is estimated without WX, i.e., a classic regression. This includes spatial Durbin models ($\\lambda = 0$), SLX error models ($\\rho = 0$), standard SLX regression ($\\rho = \\lambda = 0$), and for $\\gamma = 0$, the standard spatial error ($\\rho = 0$), spatial lag ($\\lambda = 0$ and standard regression model ($\\rho = \\lambda = 0$).\n",
    "\n",
    "The true DGP is GNS, i.e., using dgp_gns. Model estimation is OLS, so no WX taken into account and standard OLS LM diagnostics.\n",
    "\n",
    "The search strategy is the classic one from Anselin(2005), augmented by making a decision when both robust LM statistics are significant to select the one that is most significant. When the lag is selected, an additional regression is carried out for the lag model with an AK test. If the later is significant, then SARMA is selected.\n",
    "\n",
    "This rule is not applied when both robust LM statistics are not significant, but the initial LM statistics are both significant. Then the most significant is selected.\n",
    "\n",
    "This template allows for four data sets contained in the folder data_master, two p-values, SAR and MA spatial error processes and normal and lognormal error terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959587c5",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64cfaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import time\n",
    "import spreg\n",
    "import libpysal\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font\n",
    "from openpyxl.formatting.rule import CellIsRule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0816c6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pandas \",pd.__version__)\n",
    "print(\"geopandas \",gpd.__version__)\n",
    "print(\"numpy \",np.__version__)\n",
    "print(\"spreg \",spreg.__version__)\n",
    "print(\"libpysal \",libpysal.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee0317c",
   "metadata": {},
   "source": [
    "# Specify Data and Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a36990d",
   "metadata": {},
   "source": [
    "### 20x20 square grid - queen contiguity - n=400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e10296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#infileshp = \"./data_master/twentwengrid.shp\"\n",
    "#infilew = \"./data_master/grid400_q.gal\"\n",
    "#layout = \"20x20\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0732d29",
   "metadata": {},
   "source": [
    "### 40x40 square grid - queen contiguity - n=1600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72a7664",
   "metadata": {},
   "outputs": [],
   "source": [
    "#infileshp = \"./data_master/fourty40grid.shp\"\n",
    "#infilew = \"./data_master/fourty40_q.gal\"\n",
    "#layout = \"40x40\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fb13db",
   "metadata": {},
   "source": [
    "### US Counties - queen contiguity - n=3085"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2b44cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "infileshp = \"./data_master/uscounty_nodata.shp\"\n",
    "infilew = \"./data_master/uscounty_q.gal\"\n",
    "layout = \"US_counties\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0673c951",
   "metadata": {},
   "source": [
    "### Brazilian municipios - queen contiguity - n=5568"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f016fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#infileshp = \"./data_master/Brazil_nodata.shp\"\n",
    "#infilew = \"./data_master/Braz_muni_q.gal\"\n",
    "#layout = \"BRA_muni\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40625e5",
   "metadata": {},
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369a9938",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = gpd.read_file(infileshp)\n",
    "\n",
    "print(dfs.shape)\n",
    "print(list(dfs))\n",
    "\n",
    "w = libpysal.io.open(infilew).read()\n",
    "w.transform = 'r'\n",
    "n = w.n\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8463caa2",
   "metadata": {},
   "source": [
    "## Forward Specification Logic with AK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ba12bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fw_spec_ak(y,x,w=w, p_value=0.01):\n",
    "    \"\"\"\n",
    "    Forward specification: Evaluate results from LM-tests and their robust versions from spreg.OLS.\n",
    "    Estimate lag model with AK test if warranted.\n",
    "    In constrast to fw_spec, estimation is included in this function\n",
    "    Arguments:\n",
    "    ----------\n",
    "    y        : dependent variable\n",
    "    x        : matrix of explanatory variables\n",
    "    w        : spatial weights\n",
    "    \n",
    "    plmtests : reps x 5 matrix with p-values from LM tests in OLS\n",
    "               p_LM_error,p_LM_lag,p_RLM_error,p_RLM_lag,p_LM_SARMA\n",
    "    p_value  : significance threshold\n",
    "        \n",
    "    Returns:\n",
    "    ----------\n",
    "    result: the selected model as a vector\n",
    "            0 = OLS\n",
    "            1 = LAG\n",
    "            2 = ERROR\n",
    "            3 = LAGr\n",
    "            4 = ERRORr\n",
    "            5 = LAG_Br\n",
    "            6 = ERROR_Br\n",
    "            7 = LAG_Nr\n",
    "            8 = ERROR_Nr\n",
    "            9 = SARMA\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    p=p_value\n",
    "    \n",
    "    result = np.zeros((1,10))   # OLS,LAG,ERROR,LAGr,ERRORr,LAGBr,ERRORBr,LAGNr,ERROR_Nr,SARMA\n",
    "\n",
    "    model_ols_1 = spreg.OLS(y,x,w=w,slx_lags=0,spat_diag=True)\n",
    "    #print(model_ols_1.summary)\n",
    "    pvals = [model_ols_1.lm_error[1],model_ols_1.lm_lag[1],\n",
    "                             model_ols_1.rlm_error[1],model_ols_1.rlm_lag[1],\n",
    "                             model_ols_1.lm_sarma[1]]\n",
    "    \n",
    "    \n",
    "    p_error,p_lag,p_rerror,p_rlag,p_sarma = pvals\n",
    "    if p_lag>=p and p_error>=p: #First test, no LM significant= Stop and keep OLS\n",
    "        result[0,0]=1  #'OLS'\n",
    "    else : #if not SLX, go for traditional STGE approach WITH OLS (NOT SLX) RESULTS\n",
    "            #Just one significant\n",
    "        if p_lag<p and p_error>=p:\n",
    "            result[0,1] = 1 #'LAG'\n",
    "        elif p_lag>=p and p_error<p:\n",
    "            result[0,2] = 1 # 'ERROR'\n",
    "        #Both are significant (Check robust version)\n",
    "        elif p_lag<p and p_error<p:\n",
    "                #One robust significant\n",
    "            if p_rlag<p and p_rerror>=p:\n",
    "                result[0,3]= 1 #'LAGr'\n",
    "            elif p_rlag>=p and p_rerror<p:\n",
    "                result[0,4]= 1 #'ERRORr'\n",
    "                #Both robust are significant (look for the most significant)\n",
    "            elif p_rlag <p and p_rerror<p:\n",
    "                # check AK in lag model\n",
    "                try:\n",
    "                    model_lag = spreg.GM_Lag(y,x,w=w,slx_lags=0,w_lags=2,hard_bound=True)\n",
    "                    ak_lag = spreg.AKtest(model_lag,w,case='gen')\n",
    "                    if ak_lag.p <= p:\n",
    "                        result[0,9] = 1. # SARMA\n",
    "                    elif p_rlag <= p_rerror:\n",
    "                        result[0,5] = 1 # LAG_BR\n",
    "                    elif p_rlag > p_rerror:\n",
    "                        result[0,6]= 1 # 'ERROR_Br'\n",
    "                except:\n",
    "                    if p_rlag <= p_rerror:\n",
    "                        result[0,5] = 1 # LAG_BR\n",
    "                    else:\n",
    "                        result[0,6]= 1 # 'ERROR_Br'                    \n",
    "\n",
    "            else: #None robust are significant (still look for the 'most significant')\n",
    "                if p_rlag <= p_rerror:\n",
    "                    result[0,7] = 1 # 'LAG_Nr'\n",
    "                elif p_rlag > p_rerror:\n",
    "                    result[0,8] = 1 # 'ERROR_Nr'\n",
    "    #print(\"result \",result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a96a0a",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19086d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall random seed\n",
    "rndseed = 123456789\n",
    "# number of replications\n",
    "reps=1000\n",
    "# error process\n",
    "errp = 'sar'\n",
    "#errp = 'ma'\n",
    "# beta and gamma\n",
    "b1 = [1,1]\n",
    "#b1 = [1, 1, 1, 1]\n",
    "# rho range and lambda range\n",
    "rho_values = [0, 0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "lam_values = [0, 0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "# gamma range\n",
    "gam_values = [0.0, -0.5, 0.5]\n",
    "# result parameter labels\n",
    "#diagtests = ['perr', 'plag', 'prerr', 'prlag', 'psarma' ]\n",
    "models = ['OLS','LAG','ERROR','LAGr','ERRORr','LAGBr','ERRORBr','LAGNr','ERROR_Nr','SARMA']\n",
    "#k = len(diagtests)\n",
    "# Nested Dictionary to store results with the sctucture Result[rho][lam]\n",
    "# assumes only a single set of simulations is run, otherwise needs to be initialized for each run\n",
    "# Results1 is dictionary with p-values for tests\n",
    "# Modselect is dictionary with selected model\n",
    "#Results1 = {gam: {rho: {lam: {diag: [] for diag in diagtests} for lam in lam_values} \n",
    "#                   for rho in rho_values} for gam in gam_values}\n",
    "Modselect = {gam: {rho: {lam: {model: [] for model in models} for lam in lam_values} \n",
    "                   for rho in rho_values} for gam in gam_values}\n",
    "# inverse method - alternative is 'true_inv'\n",
    "invmethod = 'power_exp'\n",
    "# p-value\n",
    "pvalue = 0.01\n",
    "#pvalue = 0.05\n",
    "# error distribution\n",
    "errdist = 'normal'\n",
    "#errdist = 'lognormal'\n",
    "# number of explanatory variables\n",
    "kx = len(b1) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c141f1fb",
   "metadata": {},
   "source": [
    "## RHS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce6805f",
   "metadata": {},
   "source": [
    "X has variance 12, matched with variance 6 for error process, gives approximate R2 of 0.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8603de",
   "metadata": {},
   "outputs": [],
   "source": [
    "nk = n*kx\n",
    "var1 = 12.0/kx\n",
    "rng=np.random.default_rng(seed=rndseed) # set for X\n",
    "xx = spreg.dgp.make_x(rng,nk,mu=[0],varu=[var1],method=\"uniform\")\n",
    "if kx > 1:\n",
    "    x1 = np.reshape(xx,(n,kx))\n",
    "else:\n",
    "    x1 = xx\n",
    "xb1 = spreg.dgp.make_xb(x1,b1)\n",
    "wx1 = spreg.dgp.make_wx(x1,w) # default first order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e9b986",
   "metadata": {},
   "source": [
    "## Print Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36676719",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SETTINGS - STGE Classic Search with GNS DGP - OLS Estimation with AK\")\n",
    "print(\"Layout: \",infileshp)\n",
    "print(\"Weights: \",infilew)\n",
    "print(\"n: \",n)\n",
    "print(\"k: \",kx)\n",
    "print(\"Error Process: \",errp)\n",
    "print(\"Error Distribution: \",errdist)\n",
    "print(\"Replications: \",reps)\n",
    "print(\"p-value: \",pvalue)\n",
    "print(\"Inverse Method: \",invmethod)\n",
    "print(\"--------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec700d80",
   "metadata": {},
   "source": [
    "## Simulation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03c17e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "if errdist == 'normal':\n",
    "    vv = 6.0     # var 6 for target R2 of 0.66\n",
    "elif errdist == 'lognormal':\n",
    "    vv = 1.1     # var 1.1 for target R2 of 0.66\n",
    "else:\n",
    "    print(\"Error distribution not recognized\")    # not used\n",
    "\n",
    "\n",
    "for gam in gam_values:\n",
    "    gg=gam\n",
    "    # create a list with multiple gamma values (all same) when more than one x\n",
    "    if kx > 1:\n",
    "        g1 = np.ones(kx)*gg\n",
    "        g1 = g1.tolist()\n",
    "    else:\n",
    "        g1 = gg\n",
    "        \n",
    "    wxg1 = spreg.dgp.make_wxg(wx1,g1) \n",
    "    for rho in rho_values:\n",
    "        rho1=rho\n",
    "        for lam in lam_values:\n",
    "            lam1=lam\n",
    "            if not(rho1 + lam1 < 1):  # parameter constraint for SAR errors\n",
    "                break\n",
    "            else:\n",
    "                print(g1,rho1,lam1)\n",
    "                rng=np.random.default_rng(seed=rndseed) # reset for simulations\n",
    "                modsel = np.zeros((reps,10))\n",
    "                for i in range (reps):\n",
    "                    #print(\"i \",i)\n",
    "                    # default is normal error\n",
    "                    u= spreg.dgp.make_error(rng,n,mu=0,varu=vv,method=errdist)  # error distribution as parameter\n",
    "\n",
    "                    # DGP is GNS\n",
    "                    y1 = spreg.dgp_gns(u,xb1,wxg1,w,rho1,lam1, model= errp)\n",
    "                    # call fw_spec_ak\n",
    "                    # result is a vector of 10 0-1 indicators with 1 for the selected model\n",
    "                    result = fw_spec_ak(y1,x1,w=w,p_value=pvalue)\n",
    "                    modsel[i,:] = result\n",
    "                    \n",
    "                    #print(\"modsel \",modsel)\n",
    "                    \n",
    "                modcount = modsel.sum(axis=0)\n",
    "                modfreq = modcount / reps\n",
    "                \n",
    "                #print(\"modfreq \",modfreq)\n",
    "                    \n",
    "                for j in range(len(models)):\n",
    "                    Modselect[gam][rho][lam][models[j]] = modfreq[j]  \n",
    "                \n",
    "#print(\"modselect at end \",Modselect)\n",
    "                \n",
    "t1 = time.time()\n",
    "print(\"time in minutes: \",(t1-t0)/60.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37668dc",
   "metadata": {},
   "source": [
    "## Dictionary with Selection Frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b557f56f",
   "metadata": {},
   "source": [
    "At this point, Results is a nested dictionary with rho, lam and estimates as keys. Before we carry out forward specification, this must be turned into an array to pass to the forward specification logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493f383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenr = len(rho_values)\n",
    "lenl = len(lam_values)\n",
    "for gam in gam_values:\n",
    "    print(\"GAMMA: \",gam)\n",
    "    print(\"------------\")\n",
    "    modlag = np.zeros((lenr,lenl))\n",
    "    moderr = np.zeros((lenr,lenl))\n",
    "    for pt in range(len(models)):\n",
    "        mod = models[pt]\n",
    "        modsel = np.zeros((lenr,lenl))\n",
    "        for r in range(lenr):\n",
    "            rr = lenr -1 -r\n",
    "            for c in range(lenl):\n",
    "                rho = rho_values[r]\n",
    "                lam = lam_values[c]\n",
    "                if not(rho+lam < 1):\n",
    "                    modsel[rr,c] = np.nan\n",
    "                else:\n",
    "                    modsel[rr,c] = np.array(Modselect[gam][rho][lam][mod])\n",
    "        if mod == 'LAG':\n",
    "            modlag = modlag + modsel\n",
    "        elif mod == 'LAGr':\n",
    "            modlag = modlag + modsel\n",
    "        elif mod == 'LAGBr':\n",
    "            modlag = modlag + modsel\n",
    "        elif mod == 'LAGNr':\n",
    "            modlag = modlag + modsel\n",
    "            \n",
    "        if mod == 'ERROR':\n",
    "            moderr = moderr + modsel\n",
    "        elif mod == 'ERRORr':\n",
    "            moderr = moderr + modsel\n",
    "        elif mod == 'ERRORBr':\n",
    "            moderr = moderr + modsel\n",
    "        elif mod == 'ERROR_Nr':\n",
    "            moderr = moderr + modsel\n",
    "\n",
    "        print(\"Selection Frequency for\",mod)\n",
    "        print(modsel)\n",
    "    print(\"All Lag Selections\")\n",
    "    print(modlag)\n",
    "    print(\"All Error Selections\")\n",
    "    print(moderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731010a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is the same as previous cell, but saving in a dictionary instead of printing\n",
    "\n",
    "lenr = len(rho_values)\n",
    "lenl = len(lam_values)\n",
    "data_models={}\n",
    "for gam in gam_values:\n",
    "    data_models[gam] = {}\n",
    "    #print(\"GAMMA: \",gam)\n",
    "    #print(\"------------\")\n",
    "    modlag = np.zeros((lenr,lenl))\n",
    "    moderr = np.zeros((lenr,lenl))\n",
    "    for pt in range(len(models)):\n",
    "        mod = models[pt]\n",
    "        modsel = np.zeros((lenr,lenl))\n",
    "        for r in range(lenr):\n",
    "            rr = lenr -1 -r\n",
    "            for c in range(lenl):\n",
    "                rho = rho_values[r]\n",
    "                lam = lam_values[c]\n",
    "                if not(rho+lam < 1):\n",
    "                    modsel[rr,c] = np.nan\n",
    "                else:\n",
    "                    modsel[rr,c] = np.array(Modselect[gam][rho][lam][mod])\n",
    "        if mod == 'LAG':\n",
    "            modlag = modlag + modsel\n",
    "        elif mod == 'LAGr':\n",
    "            modlag = modlag + modsel\n",
    "        elif mod == 'LAGBr':\n",
    "            modlag = modlag + modsel\n",
    "        elif mod == 'LAGNr':\n",
    "            modlag = modlag + modsel\n",
    "            \n",
    "        if mod == 'ERROR':\n",
    "            moderr = moderr + modsel\n",
    "        elif mod == 'ERRORr':\n",
    "            moderr = moderr + modsel\n",
    "        elif mod == 'ERRORBr':\n",
    "            moderr = moderr + modsel\n",
    "        elif mod == 'ERROR_Nr':\n",
    "            moderr = moderr + modsel\n",
    "\n",
    "        data_models[gam][mod] = modsel\n",
    "        #print(\"Selection Frequency for\",mod)\n",
    "    #print(modlag)\n",
    "    data_models[gam]['LAG_'] = modlag\n",
    "    #print(\"All Error Selections\")\n",
    "    data_models[gam]['ERROR_'] = moderr\n",
    "    #print(moderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797e3c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models = ['OLS','LAG_','ERROR_', 'SARMA']\n",
    "results_models={}\n",
    "for mod in final_models:\n",
    "    data = []\n",
    "    for gam in data_models:\n",
    "        for i, rho in enumerate(rho_values):\n",
    "            for j, lam in enumerate(lam_values):\n",
    "                if rho + lam < 1:  \n",
    "                    data.append({'gamma': gam,  'rho': rho, 'lambda': lam, 'value': data_models[gam][mod][5-i,j]})\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    # Pivot the DataFrame to get the desired shape\n",
    "    pivot_df = df.pivot_table(index=['lambda', 'rho'], columns='gamma', values='value', aggfunc='first')\n",
    "    pivot_df = pivot_df.reset_index()[['rho', 'lambda', 0, -0.5, 0.5]]\n",
    "    # Save the DataFrame in the dictionary, following a specific order\n",
    "    results_models[mod] = pivot_df.iloc[[0,1,2,3,4,5,6,11,15,18,20,7,8,9,10,12,13,14,16,17,19]]\n",
    "\n",
    "#Adjusting the names \n",
    "key_map = {'LAG_': 'LAG', 'ERROR_': 'ERROR','SARMA': 'SAR-Error'}\n",
    "for old_key, new_key in key_map.items():\n",
    "    results_models[new_key] = results_models.pop(old_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8134d8",
   "metadata": {},
   "source": [
    "### Export to excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1695640",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save in Excel format\n",
    "\n",
    "with pd.ExcelWriter(f'001_STGE_Classic_{layout}_{errp}_{errdist}_p_{pvalue}.xlsx', engine='openpyxl') as writer:\n",
    "\n",
    "    ws = writer.book.create_sheet(title='Sheet1')\n",
    "\n",
    "    startrow = 0  # Initial row to start writing the dataframe\n",
    "    for name, df in results_models.items():\n",
    "        \n",
    "        # Write the dataframe name\n",
    "        ws.cell(row=startrow + 1, column=1).value = f\"{name}\"\n",
    "        \n",
    "        # Write the dataframe content\n",
    "        df.round(3).to_excel(writer, sheet_name='Sheet1', startrow=startrow + 1, index=False)       \n",
    "        # Update the startrow for the next dataframe\n",
    "        endrow = startrow + 2 + len(df)\n",
    "        startrow += len(df) + 3  \n",
    "    \n",
    "    # Apply conditional formatting to columns 3, 4, and 5 for specific value ranges\n",
    "    # Define fonts for each color\n",
    "    red_font = Font(color='FF0000')  \n",
    "    wine_font = Font(color='722F37')   \n",
    "    blue_font = Font(color='0000FF')  \n",
    "    green_font = Font(color='00FF00') \n",
    "    columns = ['C', 'D', 'E']  # Corresponding to Excel columns 3, 4, and 5\n",
    "    for col in columns:\n",
    "        \n",
    "        # Rule for Red: value > 0.95\n",
    "        ws.conditional_formatting.add(f'{col}3:{col}{endrow}',\n",
    "                                      CellIsRule(operator='greaterThan', formula=['0.95'], stopIfTrue=True, font=red_font))\n",
    "        # Rule for Wine: 0.9 < value <= 0.95\n",
    "        ws.conditional_formatting.add(f'{col}3:{col}{endrow}',\n",
    "                                      CellIsRule(operator='between', formula=['0.9', '0.95'], stopIfTrue=True, font=wine_font))\n",
    "        # Rule for Blue: 0.75 < value <= 0.9\n",
    "        ws.conditional_formatting.add(f'{col}3:{col}{endrow}',\n",
    "                                      CellIsRule(operator='between', formula=['0.75', '0.9'], stopIfTrue=True, font=blue_font))\n",
    "        # Rule for Green: 0.5 < value <= 0.75\n",
    "        ws.conditional_formatting.add(f'{col}3:{col}{endrow}',\n",
    "                                      CellIsRule(operator='between', formula=['0.5001', '0.75'], stopIfTrue=True, font=green_font))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
