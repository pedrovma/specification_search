{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6959b4d1",
   "metadata": {},
   "source": [
    "# Hybrid GETS Specification Search with GNS DGP\n",
    "\n",
    "Implements a hybrid GETS strategy starting with the estimation of an SDM specification. Based on the significance of $\\rho$ and/or $\\gamma$, this is followed by an AK test for error autocorrelation, or the estimation of an alternative OLS/SLX/Lag model, followed by an AK test.\n",
    "\n",
    "The true DGP is GNS, i.e., using dgp_gns. All alternatives are included."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959587c5",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64cfaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import time\n",
    "import spreg\n",
    "import libpysal\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font\n",
    "from openpyxl.formatting.rule import CellIsRule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0816c6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pandas \",pd.__version__)\n",
    "print(\"geopandas \",gpd.__version__)\n",
    "print(\"numpy \",np.__version__)\n",
    "print(\"spreg \",spreg.__version__)\n",
    "print(\"libpysal \",libpysal.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee0317c",
   "metadata": {},
   "source": [
    "# Specify Data and Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a36990d",
   "metadata": {},
   "source": [
    "### 20x20 square grid - queen contiguity - n=400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e10296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#infileshp = \"./data_master/twentwengrid.shp\"\n",
    "#infilew = \"./data_master/grid400_q.gal\"\n",
    "#layout = \"20x20\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0732d29",
   "metadata": {},
   "source": [
    "### 40x40 square grid - queen contiguity - n=1600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72a7664",
   "metadata": {},
   "outputs": [],
   "source": [
    "#infileshp = \"./data_master/fourty40grid.shp\"\n",
    "#infilew = \"./data_master/fourty40_q.gal\"\n",
    "#layout = \"40x40\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fb13db",
   "metadata": {},
   "source": [
    "### US Counties - queen contiguity - n=3085"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2b44cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "infileshp = \"./data_master/uscounty_nodata.shp\"\n",
    "infilew = \"./data_master/uscounty_q.gal\"\n",
    "layout = \"US_counties\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0673c951",
   "metadata": {},
   "source": [
    "### Brazilian municipios - queen contiguity - n=5568"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f016fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#infileshp = \"./data_master/Brazil_nodata.shp\"\n",
    "#infilew = \"./data_master/Braz_muni_q.gal\"\n",
    "#layout = \"BRA_muni\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40625e5",
   "metadata": {},
   "source": [
    "## Read in Data and Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369a9938",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = gpd.read_file(infileshp)\n",
    "\n",
    "print(dfs.shape)\n",
    "print(list(dfs))\n",
    "\n",
    "w = libpysal.io.open(infilew).read()\n",
    "w.transform = 'r'\n",
    "n = w.n\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8463caa2",
   "metadata": {},
   "source": [
    "## Hybrid Specification Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995ab190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_sdm(y,x, w, wlags= 2, p_value=0.01):\n",
    "    \"\"\"\n",
    "    Hybrid specification: Starting from the estimation of the Spatial Durbin model, \n",
    "                          it tests significance of coefficients and carries out specification\n",
    "                          tests for error autocorrelation to suggest the most appropriate model\n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    x: matrix of independent variables\n",
    "    y: vector of dependent variable\n",
    "    w: spatial weights matrix \n",
    "    wlags: number of spatial lags to use in S2SLS\n",
    "    p_value= significance threshold\n",
    "        \n",
    "    Returns:\n",
    "    ----------\n",
    "    result: the suggested DGP according to the specification search\n",
    "    paths:  the decision point\n",
    "            1 = common factor hypothesis in SDM = SEM\n",
    "            2 = AK test in SDM = GNS\n",
    "            3 = no error in SDM = SDM\n",
    "            4 = OLS with error = SEM\n",
    "            5 = OLS without error = OLS\n",
    "            6 = SLX with error = SLXEr\n",
    "            7 = SLX without error = SLX\n",
    "            8 = lag with error = SAREr\n",
    "            9 = lag no error = SAR\n",
    "            \n",
    "            \n",
    "    \"\"\"\n",
    "\n",
    "    # models = ['OLS','SEM','SAR','SLX','SDM','SAREr','SLXEr','GNS']\n",
    "\n",
    "    p=p_value\n",
    "    \n",
    "    k = x.shape[1]\n",
    "    model_spd = spreg.GM_Lag(y,x,w=w,slx_lags=1,w_lags=wlags,hard_bound=True)\n",
    "    #print(model_spd.summary)\n",
    "    pstats = np.array(model_spd.z_stat)[1+k:,1]         # spatial parameters\n",
    "    pk = len(pstats)\n",
    "       \n",
    "    if pstats.max() < p:  # least significant of two is still significant = SDM or GNS\n",
    "        # check on spatial common factor\n",
    "        if model_spd.cfh_test[1] >= p:    # not rejected - SEM\n",
    "            result='SEM'\n",
    "            paths = 1\n",
    "            \n",
    "        else:   # could be GNS\n",
    "            ak_sdm = spreg.AKtest(model_spd,w,case='gen')\n",
    "            if ak_sdm.p < p:    # remaining error\n",
    "                result='GNS'\n",
    "                paths = 2\n",
    "            else:\n",
    "                result='SDM'\n",
    "                paths = 3\n",
    "    \n",
    "    elif pstats.min() >= p:  # none significant - OLS or SEM\n",
    "        model_ols = spreg.OLS(y,x,w=w,spat_diag=True)\n",
    "        #print(model_ols.summary)\n",
    "        # check on LM-Error\n",
    "        errtest = spreg.LMtests(model_ols,w)\n",
    "        if errtest.lme[1] < p:   # SEM\n",
    "            result = 'SEM'\n",
    "            paths = 4\n",
    "        else:        \n",
    "            result='OLS'\n",
    "            paths = 5\n",
    "            \n",
    "    else:       # one significant and one non-sign spatial parameter\n",
    "        cand = pstats.argmax()  # non-significant one\n",
    "        if cand == (pk - 1):   # rho not sig, SLX model\n",
    "            # check error\n",
    "            model_slx = spreg.OLS(y,x,w=w,slx_lags=1,spat_diag=True)\n",
    "            #print(model_slx.summary)\n",
    "            errtest = spreg.LMtests(model_slx,w)\n",
    "            if errtest.lme[1] < p:   # SEM\n",
    "                result = 'SLXEr'\n",
    "                paths = 6\n",
    "            else:\n",
    "                result = 'SLX'\n",
    "                paths = 7\n",
    "        else:  # gamma not sign, lag model\n",
    "            model_lag = spreg.GM_Lag(y,x,w=w,slx_lags=0,w_lags=wlags,hard_bound=True)\n",
    "            #print(model_lag.summary)\n",
    "            ak_lag = spreg.AKtest(model_lag,w,case='gen')\n",
    "            if ak_lag.p < p:    # remaining error\n",
    "                result = 'SAREr'\n",
    "                paths = 8\n",
    "            else:   # no error\n",
    "                result = 'SAR'\n",
    "                paths = 9\n",
    "\n",
    "\n",
    "    return(result,paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a96a0a",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19086d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall random seed\n",
    "rndseed = 123456789\n",
    "#rndseed = 123\n",
    "# number of replications\n",
    "reps=1000\n",
    "# error process\n",
    "errp = 'sar'\n",
    "#errp = 'ma'\n",
    "# beta and gamma\n",
    "b1 = [1,1]\n",
    "#b1 = [1, 1, 1, 1]\n",
    "# rho range and lambda range\n",
    "rho_values = [0, 0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "lam_values = [0, 0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "# gamma range\n",
    "gam_values = [0.0, -0.5, 0.5]\n",
    "# result parameter labels\n",
    "models = ['OLS','SEM','SAR','SLX','SDM','SAREr','SLXEr','GNS']\n",
    "\n",
    "# Modselect is dictionary with selected model\n",
    "\n",
    "Modselect = {gam: {rho: {lam: {model: np.zeros(reps,dtype=int) for model in models} for lam in lam_values} \n",
    "                   for rho in rho_values} for gam in gam_values}\n",
    "\n",
    "# Nested dictionary with path selection for Modpaths[gam][rho][lam]\n",
    "Modpaths = {gam: {rho: {lam: np.zeros(reps,dtype=int) for lam in lam_values} \n",
    "                   for rho in rho_values} for gam in gam_values}\n",
    "\n",
    "# Nested dictionary with number of model exceptions for Modexcept[gam][rho][lam]\n",
    "Modexcept = {gam: {rho: {lam: 0 for lam in lam_values} \n",
    "                   for rho in rho_values} for gam in gam_values}\n",
    "\n",
    "# inverse method - alternative is 'true_inv'\n",
    "invmethod = 'power_exp'\n",
    "# p-value\n",
    "pvalue = 0.01\n",
    "#pvalue = 0.05\n",
    "# error distribution\n",
    "errdist = 'normal'\n",
    "#errdist = 'lognormal'\n",
    "# number of explanatory variables\n",
    "kx = len(b1) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c141f1fb",
   "metadata": {},
   "source": [
    "## RHS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce6805f",
   "metadata": {},
   "source": [
    "X has variance 12, matched with variance 6 for error process, gives approximate R2 of 0.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8603de",
   "metadata": {},
   "outputs": [],
   "source": [
    "nk = n*kx\n",
    "var1 = 12.0/kx\n",
    "rng=np.random.default_rng(seed=rndseed) # set for X\n",
    "xx = spreg.dgp.make_x(rng,nk,mu=[0],varu=[var1],method=\"uniform\")\n",
    "if kx > 1:\n",
    "    x1 = np.reshape(xx,(n,kx))\n",
    "else:\n",
    "    x1 = xx\n",
    "xb1 = spreg.dgp.make_xb(x1,b1)\n",
    "wx1 = spreg.dgp.make_wx(x1,w) # default first order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e9b986",
   "metadata": {},
   "source": [
    "## Print Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36676719",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SETTINGS - GETS Hybrid Search with GNS DGP\")\n",
    "print(\"Layout: \",infileshp)\n",
    "print(\"Weights: \",infilew)\n",
    "print(\"n: \",n)\n",
    "print(\"k: \",kx)\n",
    "print(\"Error Process: \",errp)\n",
    "print(\"Error Distribution: \",errdist)\n",
    "print(\"Replications: \",reps)\n",
    "print(\"p-value: \",pvalue)\n",
    "print(\"Inverse Method: \",invmethod)\n",
    "print(\"--------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec700d80",
   "metadata": {},
   "source": [
    "## Simulation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caf6cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "if errdist == 'normal':\n",
    "    vv = 6.0     # var 6 for target R2 of 0.66\n",
    "elif errdist == 'lognormal':\n",
    "    vv = 1.1     # var 1.1 for target R2 of 0.66\n",
    "else:\n",
    "    print(\"Error distribution not recognized\")      # not used\n",
    "\n",
    "\n",
    "for gam in gam_values:\n",
    "    gg=gam\n",
    "    # create a list with multiple gamma values (all same) when more than one x\n",
    "    if kx > 1:\n",
    "        g1 = np.ones(kx)*gg\n",
    "        g1 = g1.tolist()\n",
    "    else:\n",
    "        g1 = gg\n",
    "    \n",
    "    #print(\"gam \",g1)\n",
    "    wxg1 = spreg.dgp.make_wxg(wx1,g1) \n",
    "    for rho in rho_values:\n",
    "        rho1=rho\n",
    "        #print(\"rho \",rho1)\n",
    "        for lam in lam_values:\n",
    "            lam1=lam\n",
    "            #print(\"lam \",lam1)\n",
    "            \n",
    "            if not(rho1 + lam1 < 1):\n",
    "                break\n",
    "            else:\n",
    "                print(g1,rho1,lam1)\n",
    "                rng=np.random.default_rng(seed=rndseed) # reset for simulations\n",
    "                i=0\n",
    "                while i < reps:\n",
    "                #for i in range(reps):\n",
    "                    #print(\"i \",i)\n",
    "                    try:\n",
    "                        u=spreg.dgp.make_error(rng,n,mu=0,varu=vv,method=errdist)   # errdist as parameter\n",
    "                        # DGP is GNS\n",
    "                        y1 = spreg.dgp_gns(u,xb1,wxg1,w,rho1,lam1, model= errp)\n",
    "                        # Run backward specification\n",
    "                        model_suggested,paths = hybrid_sdm(y1,x1, w, wlags= 2, p_value=pvalue)\n",
    "                        #print(\"hybrid spec \",model_suggested,\" paths \",paths)\n",
    "                        # Append result\n",
    "                        Modselect[gam][rho][lam][model_suggested][i] = 1\n",
    "                        Modpaths[gam][rho][lam][i]=paths\n",
    "                        i += 1\n",
    "                    except:  \n",
    "                        #error_vals.append([gam,rho,lam])\n",
    "                        #print(\"except\")\n",
    "                        Modexcept[gam][rho][lam]= Modexcept[gam][rho][lam]+1\n",
    "                        if Modexcept[gam][rho][lam] > 10*reps:     #10.0*reps\n",
    "                            print(\"Gamma: \",gam,\" Rho: \",rho,\" Lambda: \",lam)\n",
    "                            print(\"Iterations stopped after \",10*reps,\" additional tries\")\n",
    "                            print(\"i = \",i)\n",
    "                            break\n",
    "                      \n",
    "\n",
    "t1 = time.time()\n",
    "print(\"time in minutes: \",(t1-t0)/60.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65851417",
   "metadata": {},
   "source": [
    "## Exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c2e9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gam in gam_values:\n",
    "    print(\"Gam: \",gam)\n",
    "    for rho in rho_values:\n",
    "        for lam in lam_values:\n",
    "            if (rho + lam < 1):\n",
    "                print(\"Rho: \",rho,\" Lambda: \",lam,\" Exceptions: \",Modexcept[gam][rho][lam])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c145d72",
   "metadata": {},
   "source": [
    "## Search Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e66734",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gam in gam_values:\n",
    "    print(\"Gam: \",gam)\n",
    "    for rho in rho_values:\n",
    "        for lam in lam_values:\n",
    "            if (rho + lam < 1):\n",
    "                pfreq = np.zeros(10,dtype=int)  # holder for counts by path\n",
    "                vp = Modpaths[gam][rho][lam]\n",
    "                vals,counts = np.unique(vp,return_counts=True)\n",
    "                pfreq[vals]=counts\n",
    "                #Modexcept[gam][rho][lam]=pfreq[0]\n",
    "                print(\" Rho: \",rho,\" Lam: \",lam,\" Path Counts: \",pfreq)\n",
    "                #print(\"Modexcept \",Modexcept)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37668dc",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2aa115",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenr = len(rho_values)\n",
    "lenl = len(lam_values)\n",
    "for gam in gam_values:\n",
    "    print(\"GAMMA: \",gam)\n",
    "    print(\"------------\")\n",
    "    for pt in range(len(models)):\n",
    "        mod = models[pt]\n",
    "        modsel = np.zeros((lenr,lenl))\n",
    "        for r in range(lenr):\n",
    "            rr = lenr - 1 -r\n",
    "            for c in range(lenl):\n",
    "                rho = rho_values[r]\n",
    "                lam = lam_values[c]\n",
    "                if not(rho+lam < 1):\n",
    "                    modsel[rr,c]= np.nan\n",
    "                else:    # divide model selection count by reps                  \n",
    "                    modpicks = Modselect[gam][rho][lam][mod]\n",
    "                    modsel[rr,c]= modpicks.sum() / reps\n",
    "        print(\"Selection Frequency for\",mod)\n",
    "        print(modsel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51a6353",
   "metadata": {},
   "source": [
    "### Export to excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9e06ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_ordered = ['OLS','SAR','SEM','SLX','SAREr','SDM','SLXEr','GNS']\n",
    "results_models={}\n",
    "\n",
    "# Save dictionary values in lists\n",
    "for mod in models_ordered:\n",
    "    data = []\n",
    "    for gam in gam_values:\n",
    "        for rho in rho_values:\n",
    "            for lam in lam_values:\n",
    "                if rho + lam < 1:  \n",
    "                    modpicks = Modselect[gam][rho][lam][mod]\n",
    "                    result= modpicks.sum() / reps\n",
    "                    data.append({'gamma': gam, 'rho': rho, 'lambda': lam, 'value': result})\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    # Pivot the DataFrame to get the desired shape\n",
    "    pivot_df = df.pivot_table(index=['lambda', 'rho'], columns='gamma', values='value', aggfunc='first')\n",
    "    pivot_df = pivot_df.reset_index()[['rho', 'lambda', 0, -0.5, 0.5]]\n",
    "    # Save the DataFrame in the dictionary, following a specific order\n",
    "    results_models[mod] = pivot_df.iloc[[0,1,2,3,4,5,6,11,15,18,20,7,8,9,10,12,13,14,16,17,19]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eb2a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save in Excel format\n",
    "\n",
    "with pd.ExcelWriter(f'004_GETS_SDM_{layout}_{errp}_{errdist}_p_{pvalue}.xlsx', engine='openpyxl') as writer:\n",
    "\n",
    "    ws = writer.book.create_sheet(title='Sheet1')\n",
    "\n",
    "    startrow = 0  # Initial row to start writing the dataframe\n",
    "    for name, df in results_models.items():\n",
    "        \n",
    "        # Write the dataframe name\n",
    "        ws.cell(row=startrow + 1, column=1).value = f\"{name}\"\n",
    "        \n",
    "        # Write the dataframe content\n",
    "        df.round(3).to_excel(writer, sheet_name='Sheet1', startrow=startrow + 1, index=False)       \n",
    "        # Update the startrow for the next dataframe\n",
    "        endrow = startrow + 2 + len(df)\n",
    "        startrow += len(df) + 3  \n",
    "    \n",
    "    # Apply conditional formatting to columns 3, 4, and 5 for specific value ranges\n",
    "    # Define fonts for each color\n",
    "    red_font = Font(color='FF0000')  \n",
    "    wine_font = Font(color='722F37')   \n",
    "    blue_font = Font(color='0000FF')  \n",
    "    green_font = Font(color='00FF00') \n",
    "    columns = ['C', 'D', 'E']  # Corresponding to Excel columns 3, 4, and 5\n",
    "    for col in columns:\n",
    "        \n",
    "        # Rule for Red: value > 0.95\n",
    "        ws.conditional_formatting.add(f'{col}3:{col}{endrow}',\n",
    "                                      CellIsRule(operator='greaterThan', formula=['0.95'], stopIfTrue=True, font=red_font))\n",
    "        # Rule for Wine: 0.9 < value <= 0.95\n",
    "        ws.conditional_formatting.add(f'{col}3:{col}{endrow}',\n",
    "                                      CellIsRule(operator='between', formula=['0.9', '0.95'], stopIfTrue=True, font=wine_font))\n",
    "        # Rule for Blue: 0.75 < value <= 0.9\n",
    "        ws.conditional_formatting.add(f'{col}3:{col}{endrow}',\n",
    "                                      CellIsRule(operator='between', formula=['0.75', '0.9'], stopIfTrue=True, font=blue_font))\n",
    "        # Rule for Green: 0.5 < value <= 0.75\n",
    "        ws.conditional_formatting.add(f'{col}3:{col}{endrow}',\n",
    "                                      CellIsRule(operator='between', formula=['0.5001', '0.75'], stopIfTrue=True, font=green_font))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
